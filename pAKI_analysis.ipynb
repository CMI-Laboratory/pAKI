{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from functools import partial\n",
    "from itertools import cycle, islice\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import warnings\n",
    "from sklearn import datasets, metrics, linear_model, svm\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.datasets import (make_moons, make_circles, make_classification, \n",
    "                             make_blobs, make_checkerboard)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              ExtraTreesClassifier, GradientBoostingClassifier, \n",
    "                              BaggingClassifier, VotingClassifier)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from scipy import interp\n",
    "from tableone import TableOne\n",
    "import shap\n",
    "from auto_shap.auto_shap import generate_shap_values\n",
    "\n",
    "def set_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207e04f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final=pd.read_csv('20240727_AKI_data.csv',encoding='cp949')\n",
    "print('total n')\n",
    "print(len(df_final))\n",
    "\n",
    "df_final_columns=list(df_final.columns)\n",
    "df_final_columns2=[x for x in df_final_columns if '_avail' not in x]\n",
    "df_final2=df_final[df_final_columns2]\n",
    "y=list(df_final2['AKI_postop_7D'])\n",
    "y2=list(df_final2['AKI_nonrecov_7D'])\n",
    "y3=list(df_final2['AKI_sustained_48'])\n",
    "y4=list(df_final2['AKI_sustained_72'])\n",
    "ThakarScore=list(df_final2['ThakarScore'])\n",
    "CKD_eGFR_stage=list(df_final2['CKD_eGFR_stage'])\n",
    "\n",
    "print('AKI incidence')\n",
    "print(np.sum(y))\n",
    "print(np.sum(y)/len(df_final2))\n",
    "print('')\n",
    "\n",
    "print('AKI nonrecovery incidence')\n",
    "print(np.sum(y2))\n",
    "print(np.sum(y2)/len(df_final2))\n",
    "print('')\n",
    "\n",
    "print('AKI_sustained_48 incidence')\n",
    "print(np.sum(y3))\n",
    "print(np.sum(y3)/len(df_final2))\n",
    "print('')\n",
    "\n",
    "print('AKI_sustained_72 incidence')\n",
    "print(np.sum(y4))\n",
    "print(np.sum(y4)/len(df_final2))\n",
    "print('')\n",
    "\n",
    "\n",
    "print('AUROC, AUPRC of ThakarScore')\n",
    "fpr, tpr, thresholds = roc_curve(y, ThakarScore)\n",
    "auroc = auc(fpr, tpr)\n",
    "precision, recall, _ = precision_recall_curve(y, ThakarScore)\n",
    "auprc = auc(recall, precision)\n",
    "print(auroc,auprc)\n",
    "\n",
    "print('AUROC, AUPRC of CKD_eGFR_stage')\n",
    "fpr, tpr, thresholds = roc_curve(y, CKD_eGFR_stage)\n",
    "auroc = auc(fpr, tpr)\n",
    "precision, recall, _ = precision_recall_curve(y, CKD_eGFR_stage)\n",
    "auprc = auc(recall, precision)\n",
    "print(auroc,auprc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d273d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 1 year\n",
    "X_trainval=df_final2.iloc[:1693]\n",
    "X_test=df_final2.iloc[1693:]\n",
    "X_trainval.reset_index(inplace=True,drop=True)\n",
    "X_test.reset_index(inplace=True,drop=True)\n",
    "\n",
    "X_trainval=X_trainval[list(X_trainval.columns)[:-5]]\n",
    "X_test=X_test[list(X_test.columns)[:-5]]\n",
    "\n",
    "X_trainval = X_trainval.drop(columns=list(X_trainval.columns)[-11:-8])\n",
    "X_test = X_test.drop(columns=list(X_test.columns)[-11:-8])\n",
    "\n",
    "yy_trainval=y[:1693]\n",
    "yy_test=y[1693:]\n",
    "\n",
    "yy2_trainval=y2[:1693]\n",
    "yy2_test=y2[1693:]\n",
    "\n",
    "yy3_trainval=y3[:1693]\n",
    "yy3_test=y3[1693:]\n",
    "\n",
    "yy4_trainval=y4[:1693]\n",
    "yy4_test=y4[1693:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5727c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainvaltest=pd.concat([X_trainval,X_test])\n",
    "y_trainvaltest=yy4_trainval+yy4_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7872dee6",
   "metadata": {},
   "source": [
    "# scenario columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8cc2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=list(X_trainval.columns)\n",
    "\n",
    "input_model0_1=columns[:34]\n",
    "input_model1_1=columns[34:40]\n",
    "input_model0_2=columns[40:62]\n",
    "input_model1_2=columns[62:87]\n",
    "etccols=columns[87:]\n",
    "input_model2_1=columns[155:-2]\n",
    "\n",
    "scenario1=[]\n",
    "scenario1.append('baseline_rSO2')\n",
    "scenario1.append('MAP_mean_list')\n",
    "scenario1.append('MAP_CV_list')\n",
    "scenario1.append('MAP_ARV_list')\n",
    "scenario1.append('MAP_duration_65_list')\n",
    "scenario1.append('MAP_duration_100_list')\n",
    "scenario1.append('MAP_auc_65_list')\n",
    "scenario1.append('MAP_auc_100_list')\n",
    "scenario1.append('PP_mean_list')\n",
    "scenario1.append('PP_duration_60_list')\n",
    "scenario1.append('PP_auc_60_list')\n",
    "scenario1.append('CVP_mean_list')\n",
    "scenario1.append('CVP_duration_12_list')\n",
    "scenario1.append('CVP_auc_12_list')\n",
    "scenario1.append('CI_mean_list')\n",
    "scenario1.append('CI_duration_2_list')\n",
    "scenario1.append('CI_auc_2_list')\n",
    "\n",
    "scenario2=[]\n",
    "scenario2.append('baseline_rSO2')\n",
    "scenario2.append('NEW_MAP_preCPB_CV_list')\n",
    "scenario2.append('NEW_MAP_preCPB_ARV_list')\n",
    "scenario2.append('NEW_PP_preCPB_mean_list')\n",
    "scenario2.append('NEW_PP_preCPB_auc_60_list')\n",
    "scenario2.append('NEW_CI_preCPB_mean_list')\n",
    "scenario2.append('NEW_CI_preCPB_auc_2_list')\n",
    "scenario2.append('NEW_MAP_intraCPB_CV_list')\n",
    "scenario2.append('NEW_MAP_intraCPB_ARV_list')\n",
    "scenario2.append('NEW_MAP_postCPB_CV_list')\n",
    "scenario2.append('NEW_MAP_postCPB_ARV_list')\n",
    "scenario2.append('NEW_PP_postCPB_mean_list')\n",
    "scenario2.append('NEW_PP_postCPB_auc_60_list')\n",
    "scenario2.append('NEW_CI_postCPB_mean_list')\n",
    "scenario2.append('NEW_CI_postCPB_auc_2_list')\n",
    "\n",
    "scenario3=[]\n",
    "scenario3.append('baseline_rSO2')\n",
    "scenario3.append('MAP_CV_list')\n",
    "scenario3.append('MAP_ARV_list')\n",
    "scenario3.append('NEW_PP_CPBMAPincluded_mean_list')\n",
    "scenario3.append('NEW_PP_CPBMAPincluded_auc_60_list')\n",
    "scenario3.append('CI_mean_list')\n",
    "scenario3.append('CI_auc_2_list')\n",
    "\n",
    "\n",
    "scenario4=[]\n",
    "scenario4.append('baseline_rSO2')\n",
    "scenario4.append('MAP_mean_list')\n",
    "scenario4.append('MAP_CV_list')\n",
    "scenario4.append('MAP_ARV_list')\n",
    "scenario4.append('MAP_duration_65_list')\n",
    "scenario4.append('MAP_duration_100_list')\n",
    "scenario4.append('MAP_auc_65_list')\n",
    "scenario4.append('MAP_auc_100_list')\n",
    "scenario4.append('PP_mean_list')\n",
    "scenario4.append('PP_duration_60_list')\n",
    "scenario4.append('PP_auc_60_list')\n",
    "scenario4.append('CVP_mean_list')\n",
    "scenario4.append('CVP_duration_12_list')\n",
    "scenario4.append('CVP_auc_12_list')\n",
    "scenario4.append('CI_mean_list')\n",
    "scenario4.append('CI_duration_2_list')\n",
    "scenario4.append('CI_auc_2_list')\n",
    "scenario4.append('NEW_MAP_intraCPB_mean_list')\n",
    "scenario4.append('NEW_MAP_intraCPB_duration_65_list')\n",
    "scenario4.append('NEW_MAP_intraCPB_duration_100_list')\n",
    "scenario4.append('NEW_MAP_intraCPB_auc_65_list')\n",
    "scenario4.append('NEW_MAP_intraCPB_auc_100_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e11247",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_model0=input_model0_1+input_model0_2\n",
    "\n",
    "input_model1=input_model0+input_model1_1+input_model1_2+scenario2\n",
    "\n",
    "input_model2=input_model1+input_model2_1\n",
    "\n",
    "X_trainval_model0=X_trainval[input_model0]\n",
    "X_trainval_model1=X_trainval[input_model1]\n",
    "X_trainval_model2=X_trainval[input_model2]\n",
    "\n",
    "X_test_model0=X_test[input_model0]\n",
    "X_test_model1=X_test[input_model1]\n",
    "X_test_model2=X_test[input_model2]\n",
    "\n",
    "\n",
    "y_trainval=np.array(yy4_trainval)\n",
    "y_test=np.array(yy4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b31c782-e825-4ca7-a617-5d0cb39f4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = pd.concat([X_trainval_model2, X_test_model2], axis=0, ignore_index=True)\n",
    "y_combined = np.concatenate([y_trainval, y_test])\n",
    "X_combined['pAKI']=y_combined\n",
    "df_combined=X_combined.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0dc631",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a372c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seeds(0)\n",
    "model = xgb.XGBClassifier()\n",
    "parameter_space = {\n",
    "    'n_estimators': [100, 200, 300, 400],            # Number of boosted trees to fit\n",
    "    'max_depth': [2,3, 4, 5, 6, 7, 8, 9],                      # Maximum tree depth for base learners\n",
    "    'learning_rate': [0.0001,0.001, 0.01, 0.1],        # Step size shrinkage used to prevent overfitting\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],                   # Subsample ratio of the training instance\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],            # Subsample ratio of columns when constructing each tree\n",
    "    'gamma': [0,  0.5, 1, 2, 4, 8],                    # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    'reg_alpha': [0, 0.5, 1, 2, 4, 8],                  # L1 regularization term on weights\n",
    "    'reg_lambda': [0, 0.5, 1, 2, 4, 8],                      # L2 regularization term on weights\n",
    "    'min_child_weight': [1, 2, 3, 4]                   # Minimum sum of instance weight (hessian) needed in a child\n",
    "}\n",
    "\n",
    "folds = 4\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "              \n",
    "grid_search = GridSearchCV(model, parameter_space, scoring=['roc_auc', 'average_precision'], verbose=2, return_train_score=True, cv=skf, refit='roc_auc')\n",
    "\n",
    "grid_search.fit(X_trainval_model0, y_trainval)\n",
    "best_param = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d0adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_XGB=xgb.XGBClassifier(**best_param)\n",
    "set_seeds(0)\n",
    "classifier_XGB.fit(X_trainval_model0, y_trainval)\n",
    "probas_ = classifier_XGB.predict_proba(X_test_model0)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "print(auc(fpr, tpr))\n",
    "precision, recall, _ = precision_recall_curve(y_test, probas_[:, 1])\n",
    "print(auc(recall, precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fb72a1",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19f21a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seeds(0)\n",
    "model = RandomForestClassifier()\n",
    "parameter_space = {\n",
    "    'criterion':['log_loss','gini','entropy'],\n",
    "    'n_estimators': [25,50, 100, 150, 200,250,300],  # Number of trees\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10,12],  # Maximum tree depth\n",
    "    'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10],  # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 3, 4],  # Minimum samples required to be at a leaf node\n",
    "    'max_features': ['sqrt', 'log2', None]  # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "folds = 4\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "              \n",
    "grid_search = GridSearchCV(model, parameter_space, scoring=['roc_auc', 'average_precision'], verbose=2, return_train_score=True, cv=skf, refit='roc_auc')\n",
    "\n",
    "grid_search.fit(X_trainval_model0, y_trainval)\n",
    "best_param = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6816a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_RF=RandomForestClassifier(**best_param)\n",
    "set_seeds(0)\n",
    "classifier_RF.fit(X_trainval_model0, y_trainval)\n",
    "probas_ = classifier_RF.predict_proba(X_test_model0)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "print(auc(fpr, tpr))\n",
    "precision, recall, _ = precision_recall_curve(y_test, probas_[:, 1])\n",
    "print(auc(recall, precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b011071",
   "metadata": {},
   "source": [
    "# ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ed25b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seeds(42)\n",
    "model = et()\n",
    "parameter_space = {\n",
    "    'n_estimators': [50, 100, 150, 200,250,300],  # Number of trees\n",
    "    'criterion': ['gini', 'entropy'],  # Splitting criterion\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],  # Maximum tree depth\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum samples required to be at a leaf node\n",
    "    'max_features': ['sqrt', 'log2', None],  # Number of features to consider when looking for the best split\n",
    "    'bootstrap': [False, True],  # Whether bootstrap samples are used when building trees\n",
    "    'class_weight': [None, 'balanced']  # Weights associated with classes\n",
    "}\n",
    "\n",
    "parameter_space = {\n",
    "    'n_estimators': [50, 100, 150],  # Number of trees\n",
    "}\n",
    "\n",
    "folds = 4\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "              \n",
    "grid_search = GridSearchCV(model, parameter_space, scoring=['roc_auc', 'average_precision'], verbose=2, return_train_score=True, cv=skf, refit='roc_auc')\n",
    "\n",
    "grid_search.fit(X_trainval_model0, y_trainval)\n",
    "best_param = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8809128",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_ET=et(**best_param)\n",
    "set_seeds(0)\n",
    "classifier_ET.fit(X_trainval_model0, y_trainval)\n",
    "probas_ = classifier_ET.predict_proba(X_test_model0)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "print(auc(fpr, tpr))\n",
    "precision, recall, _ = precision_recall_curve(y_test, probas_[:, 1])\n",
    "print(auc(recall, precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a400d9b",
   "metadata": {},
   "source": [
    "# ENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = VotingClassifier(estimators=[('XGB', classifier_XGB),('RF', classifier_RF),('ET', classifier_ET)], voting='soft')\n",
    "set_seeds(0)\n",
    "clf.fit(X_trainval_model0, y_trainval)\n",
    "probas_ = clf.predict_proba(X_test_model0)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_[:,1])\n",
    "auroc = auc(fpr, tpr)\n",
    "precision, recall, _ = precision_recall_curve(y_test, probas_[:, 1])\n",
    "auprc = auc(recall, precision)\n",
    "print(auroc,auprc)\n",
    "joblib.dump(clf, \"20240820_models/ENS_classifier.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6692a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values, shap_expected_value, global_shap_df = generate_shap_values(clf, X_test_model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b71807",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_np=shap_values.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4549fb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_np,X_test_model0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815acb8",
   "metadata": {},
   "source": [
    "# tableOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7631683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table1(catcolumn,catcolumns,dfdfdf2,savename):\n",
    "    nonnormallist=[]\n",
    "    def _normality(self, x):\n",
    "        #print(x.name)\n",
    "\n",
    "        if len(x.values[~np.isnan(x.values)]) >= 20:\n",
    "            p = stats.shapiro(x.values).pvalue\n",
    "        else:\n",
    "            p = None\n",
    "        # dropna=False argument in pivot_table does not function as expected\n",
    "        # return -1 instead of None\n",
    "        if pd.isnull(p):\n",
    "            return -1\n",
    "        if p<=0.05:\n",
    "            nonnormallist.append(x.name)\n",
    "        return p\n",
    "\n",
    "    TableOne._normality=_normality\n",
    "\n",
    "    def my_custom_test(group1, group2):\n",
    "        \"\"\"\n",
    "        Hypothesis test for test_self_defined_statistical_tests\n",
    "        \"\"\"\n",
    "        my_custom_test.__name__ = \"mannwhitneyu\"\n",
    "        _, pval= scipy.stats.mannwhitneyu(group1, group2)\n",
    "        return pval\n",
    "\n",
    "    nonnormallist=[]\n",
    "    def _normality(self, x):\n",
    "        #print(x.name)\n",
    "\n",
    "        if len(x.values[~np.isnan(x.values)]) >= 20:\n",
    "            p = stats.shapiro(x.values).pvalue\n",
    "        else:\n",
    "            p = None\n",
    "        # dropna=False argument in pivot_table does not function as expected\n",
    "        # return -1 instead of None\n",
    "        if pd.isnull(p):\n",
    "            return -1\n",
    "        if p<=0.05:\n",
    "            nonnormallist.append(x.name)\n",
    "        return p\n",
    "\n",
    "    TableOne._normality=_normality\n",
    "\n",
    "    table1=TableOne(dfdfdf2,categorical=catcolumns,groupby=[catcolumn],normal_test=True,pval=True,htest_name=True,decimals=3)\n",
    "    nonnormallist=list(set(nonnormallist))\n",
    "    nonnormallist\n",
    "\n",
    "    table1=TableOne(dfdfdf2,categorical=catcolumns,groupby=[catcolumn],normal_test=True,pval=True,htest_name=True,nonnormal=nonnormallist,decimals=3)\n",
    "    try:\n",
    "        os.mkdir(newtablename)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir(newtablename+'/table1')\n",
    "    except:\n",
    "        pass\n",
    "    catcolumn=catcolumn.replace(' ','_')\n",
    "    catcolumn=catcolumn.replace('/','_')\n",
    "    table1.to_html('figures/table1_'+savename+'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical=[]\n",
    "categorical.append('op_type')\n",
    "categorical.append('re-do')\n",
    "categorical.append('sex')\n",
    "categorical.append('emergency')\n",
    "categorical.append('VAD_use')\n",
    "categorical.append('HTN')\n",
    "categorical.append('CKD')\n",
    "categorical.append('old CVA')\n",
    "categorical.append('DM')\n",
    "categorical.append('A.fib')\n",
    "categorical.append('liver cirrhosis')\n",
    "categorical.append('CHF')\n",
    "categorical.append('old MI')\n",
    "categorical.append('COPD')\n",
    "categorical.append('Functional class')\n",
    "categorical.append('acuteMI (1WK)')\n",
    "categorical.append('NYHA')\n",
    "categorical.append('BB')\n",
    "categorical.append('CCB')\n",
    "categorical.append('ACEi')\n",
    "categorical.append('ARB')\n",
    "categorical.append('Statin')\n",
    "categorical.append('diuretics')\n",
    "categorical.append('Warfarin')\n",
    "categorical.append('heparinization')\n",
    "categorical.append('NOAC')\n",
    "categorical.append('vaso_T')\n",
    "categorical.append('prima_T_bi')\n",
    "categorical.append('dobu_T_bi')\n",
    "categorical.append('Katz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c0d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainvaltest2=X_trainvaltest.copy()\n",
    "X_trainvaltest2['y']=y_trainvaltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90890c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table1('y',categorical,X_trainvaltest2, 'y4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a77198",
   "metadata": {},
   "source": [
    "# ROC PR curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6299bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_PR_curves(roc_pr):\n",
    "    fig, ax =plt.subplots(figsize=(25,25))\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('black')\n",
    "        spine.set_linewidth(2)  # Adjust the line width as needed\n",
    "\n",
    "    if roc_pr=='ROC':\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',alpha=1)\n",
    "    plt.xticks(fontsize=28)\n",
    "    plt.yticks(fontsize=28)\n",
    "    \n",
    "\n",
    "    clf_loaded = joblib.load('20240820_models/ENS_classifier.pkl')\n",
    "    set_seeds(0)\n",
    "    probas_ = clf_loaded.predict_proba(X_test_model0)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "    auroc = round(auc(fpr, tpr),3)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, probas_[:, 1])\n",
    "    auprc = round(auc(recall, precision),3)\n",
    "            \n",
    "    linewidth=3\n",
    "    \n",
    "    if roc_pr=='ROC':\n",
    "        plt.plot(fpr, tpr, color='blue',label=f'ENS model AUROC = {auroc}' ,lw=linewidth, alpha=1)\n",
    "    if roc_pr=='PR':\n",
    "        plt.plot(recall, precision, color='blue',label=f'ENS model AUPRC = {auprc}' ,lw=linewidth, alpha=1)\n",
    "    \n",
    "    plt.xlim([-0.00, 1.00])\n",
    "    plt.ylim([-0.00, 1.00])\n",
    "    plt.yticks(np.arange(0.2, 1.2, step=0.2))\n",
    "    plt.xticks(fontsize =37)\n",
    "    plt.yticks(fontsize =37)\n",
    "    \n",
    "    if roc_pr == 'ROC':\n",
    "        plt.xlabel('1-Specificity', fontsize=50)\n",
    "        plt.ylabel('Sensitivity', fontsize=50)\n",
    "        plt.title('ROC curves', fontsize=55)\n",
    "        legend = plt.legend(loc=\"lower right\", fontsize=45)\n",
    "    if roc_pr == 'PR':\n",
    "        plt.xlabel('Recall', fontsize=50)\n",
    "        plt.ylabel('Precision', fontsize=50)\n",
    "        plt.title('PR curves', fontsize=55)\n",
    "        legend = plt.legend(loc=\"upper right\", fontsize=45)\n",
    "    \n",
    "    # Set line width of legend box\n",
    "    legend.get_frame().set_linewidth(4)\n",
    "    \n",
    "    # Set line width of legend lines\n",
    "    for line in legend.get_lines():\n",
    "        line.set_linewidth(8)  # Adjust the line width as needed\n",
    "    \n",
    "    if roc_pr == 'ROC':\n",
    "        plt.savefig('figures/20230821_ROC.png', transparent=True)\n",
    "        plt.show()\n",
    "    if roc_pr == 'PR':\n",
    "        plt.savefig('figures/20230821_PR.png', transparent=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bad2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rocprtemp in ['ROC','PR']:\n",
    "    ROC_PR_curves(roc_pr=rocprtemp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d83224-1d68-4d26-925e-821f0f61a89b",
   "metadata": {},
   "source": [
    "# Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547a1ba0-080e-40b7-a323-57444c76ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "def performance_table():\n",
    "    \n",
    "    clf_loaded = joblib.load('20240820_models/ENS_classifier.pkl')\n",
    "    set_seeds(0)\n",
    "    probas_ = clf_loaded.predict_proba(X_test_model0)\n",
    "    y_pred = clf_loaded.predict(X_test_model0)\n",
    "    \n",
    "    auroc = roc_auc_score(y_test, probas_[:, 1])\n",
    "    auprc = average_precision_score(y_test, probas_[:, 1])\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    ppv = tp / (tp + fp)\n",
    "    npv = tn / (tn + fn)\n",
    "    \n",
    "    results = {\n",
    "        'Metric': ['AUROC', 'AUPRC', 'Accuracy', 'Sensitivity', 'Specificity', 'PPV', 'NPV', 'F1-score'],\n",
    "        'Value': [auroc, auprc, accuracy, sensitivity, specificity, ppv, npv, f1]\n",
    "    }\n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results['Value'] = df_results['Value'].round(4)\n",
    "    \n",
    "    print(df_results)\n",
    "    df_results.to_csv('figures/performance_metrics.csv', index=False)\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae1157-20b6-45dc-a4d2-e4a189db3340",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348473b8-0d96-4da1-9b74-c59ef59e391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_pred_proba):\n",
    "    \n",
    "    auroc = roc_auc_score(y_true, y_pred_proba)\n",
    "    auprc = average_precision_score(y_true, y_pred_proba)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "    \n",
    "    return [auroc, auprc, accuracy, sensitivity, specificity, ppv, npv, f1]\n",
    "\n",
    "def bootstrap_ci():\n",
    "    \n",
    "    clf_loaded = joblib.load('20240820_models/ENS_classifier.pkl')\n",
    "    set_seeds(0)\n",
    "    probas_ = clf_loaded.predict_proba(X_test_model0)\n",
    "    y_pred = clf_loaded.predict(X_test_model0)\n",
    "    \n",
    "    n_bootstraps = 2000\n",
    "    bootstrapped_scores = []\n",
    "    \n",
    "    for i in range(n_bootstraps):\n",
    "        indices = resample(range(len(y_test)), n_samples=len(y_test), random_state=i)\n",
    "        \n",
    "        y_test_boot = [y_test[idx] for idx in indices]\n",
    "        y_pred_boot = y_pred[indices]\n",
    "        y_pred_proba_boot = probas_[indices, 1]\n",
    "        \n",
    "        scores = calculate_metrics(y_test_boot, y_pred_boot, y_pred_proba_boot)\n",
    "        bootstrapped_scores.append(scores)\n",
    "    \n",
    "    bootstrapped_scores = np.array(bootstrapped_scores)\n",
    "    \n",
    "    original_scores = calculate_metrics(y_test, y_pred, probas_[:, 1])\n",
    "    \n",
    "    lower_bound = np.percentile(bootstrapped_scores, 2.5, axis=0)\n",
    "    upper_bound = np.percentile(bootstrapped_scores, 97.5, axis=0)\n",
    "    \n",
    "    results = {\n",
    "        'Metric': ['AUROC', 'AUPRC', 'Accuracy', 'Sensitivity', 'Specificity', 'PPV', 'NPV', 'F1-score'],\n",
    "        'Value': original_scores,\n",
    "        'Lower_CI': lower_bound,\n",
    "        'Upper_CI': upper_bound\n",
    "    }\n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results['Value'] = df_results['Value'].round(4)\n",
    "    df_results['Lower_CI'] = df_results['Lower_CI'].round(4)\n",
    "    df_results['Upper_CI'] = df_results['Upper_CI'].round(4)\n",
    "    df_results['95% CI'] = df_results.apply(lambda row: f\"({row['Lower_CI']}, {row['Upper_CI']})\", axis=1)\n",
    "    \n",
    "    df_final = df_results[['Metric', 'Value', '95% CI']]\n",
    "    \n",
    "    print(df_final)\n",
    "    df_final.to_csv('figures/performance_metrics_with_CI.csv', index=False)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f374bed-022c-4e2a-9cee-471a04c11e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_ci()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89113701-2990-4b31-867e-5efe4a8426f8",
   "metadata": {},
   "source": [
    "## NRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4396d8-b539-46bf-9664-de8dc9c1aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nri():\n",
    "    \n",
    "    clf_loaded = joblib.load('20240820_models/ENS_classifier.pkl')\n",
    "    set_seeds(0)\n",
    "    probas_ = clf_loaded.predict_proba(X_test_model0)\n",
    "    \n",
    "    thakar_scores = X_test_model0['ThakarScore'].values\n",
    "    model_probs = probas_[:, 1]\n",
    "    \n",
    "    threshold = 0.5\n",
    "    \n",
    "    thakar_pred = (thakar_scores >= threshold).astype(int)\n",
    "    model_pred = (model_probs >= threshold).astype(int)\n",
    "    \n",
    "    events = np.array(y_test) == 1\n",
    "    non_events = np.array(y_test) == 0\n",
    "    \n",
    "    up_events = np.sum((model_pred > thakar_pred) & events)\n",
    "    down_events = np.sum((model_pred < thakar_pred) & events)\n",
    "    total_events = np.sum(events)\n",
    "    \n",
    "    up_non_events = np.sum((model_pred > thakar_pred) & non_events)\n",
    "    down_non_events = np.sum((model_pred < thakar_pred) & non_events)\n",
    "    total_non_events = np.sum(non_events)\n",
    "    \n",
    "    nri_events = (up_events - down_events) / total_events\n",
    "    nri_non_events = (down_non_events - up_non_events) / total_non_events\n",
    "    \n",
    "    nri = nri_events + nri_non_events\n",
    "    \n",
    "    results = {\n",
    "        'Metric': ['NRI (Events)', 'NRI (Non-events)', 'Total NRI'],\n",
    "        'Value': [nri_events, nri_non_events, nri]\n",
    "    }\n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results['Value'] = df_results['Value'].round(4)\n",
    "    \n",
    "    print(df_results)\n",
    "    df_results.to_csv('figures/NRI.csv', index=False)\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "calculate_nri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e25391c-5701-4cf2-9b26-7bc7dd20c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_nri()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3a16ba-6fa2-4e63-9565-4286d3b7ba0b",
   "metadata": {},
   "source": [
    "## regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af778233-7629-45ff-b34e-7993349eb6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import stats\n",
    "\n",
    "def adjusted_odds_ratio():\n",
    "    \n",
    "    clf_loaded = joblib.load('20240820_models/ENS_classifier.pkl')\n",
    "    set_seeds(0)\n",
    "    probas_ = clf_loaded.predict_proba(X_test_model0)\n",
    "    \n",
    "    ml_output_scaled = probas_[:, 1] * 10\n",
    "    \n",
    "    euroscore = X_test_model0['euroSCORE II'].values\n",
    "    ihm = X_test_model0['IHM'].values\n",
    "    \n",
    "    X_logistic = np.column_stack([ml_output_scaled, euroscore])\n",
    "    y_logistic = ihm\n",
    "    \n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "    log_reg.fit(X_logistic, y_logistic)\n",
    "    \n",
    "    coef_ml = log_reg.coef_[0][0]\n",
    "    or_ml = np.exp(coef_ml)\n",
    "    \n",
    "    X_with_intercept = np.column_stack([np.ones(len(X_logistic)), X_logistic])\n",
    "    \n",
    "    predictions = log_reg.predict_proba(X_logistic)[:, 1]\n",
    "    W = np.diag(predictions * (1 - predictions))\n",
    "    \n",
    "    variance_covariance = np.linalg.inv(X_with_intercept.T @ W @ X_with_intercept)\n",
    "    \n",
    "    se_ml = np.sqrt(variance_covariance[1, 1])\n",
    "    \n",
    "    z_score = 1.96\n",
    "    ci_lower = np.exp(coef_ml - z_score * se_ml)\n",
    "    ci_upper = np.exp(coef_ml + z_score * se_ml)\n",
    "    \n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(coef_ml / se_ml)))\n",
    "    \n",
    "    results = {\n",
    "        'Variable': ['ML Model Output (per 0.1 increase)'],\n",
    "        'OR': [or_ml],\n",
    "        'Lower_CI': [ci_lower],\n",
    "        'Upper_CI': [ci_upper],\n",
    "        'P_value': [p_value]\n",
    "    }\n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results['OR'] = df_results['OR'].round(4)\n",
    "    df_results['Lower_CI'] = df_results['Lower_CI'].round(4)\n",
    "    df_results['Upper_CI'] = df_results['Upper_CI'].round(4)\n",
    "    df_results['P_value'] = df_results['P_value'].round(4)\n",
    "    df_results['95% CI'] = df_results.apply(lambda row: f\"({row['Lower_CI']}, {row['Upper_CI']})\", axis=1)\n",
    "    \n",
    "    df_final = df_results[['Variable', 'OR', '95% CI', 'P_value']]\n",
    "    \n",
    "    print(df_final)\n",
    "    df_final.to_csv('figures/adjusted_OR.csv', index=False)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ffbc3-796b-411c-81ca-e4b584974532",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_odds_ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d7c40",
   "metadata": {},
   "source": [
    "# SHAP summary plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SHAP_summary_plot():\n",
    "    \n",
    "    clf_loaded = joblib.load('20240820_models/ENS_classifier.pkl')\n",
    "    set_seeds(0)\n",
    "\n",
    "    shap_values, shap_expected_value, global_shap_df = generate_shap_values(clf_loaded, X_test_model0)\n",
    "    shap_values_np=shap_values.to_numpy()\n",
    "\n",
    "    shap.summary_plot(shap_values_np,X_test_model0,max_display=10,show=False)\n",
    "    savename='figures/20241010_SHAP_summary.png'\n",
    "    plt.savefig(savename,transparent=True)\n",
    "\n",
    "    plt.close()\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69489fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAP_summary_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477ac8d1",
   "metadata": {},
   "source": [
    "# SHAP dependence plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SHAP_dependence_plot(X_test,model_type,scenario_num, y_trainval, y_test,excludelistnum,ytype,seednum):\n",
    "\n",
    "    clf_loaded = joblib.load('20240820_models/ENS_classifier.pkl')\n",
    "    set_seeds(0)\n",
    "   \n",
    "    shap_values, shap_expected_value, global_shap_df = generate_shap_values(clf_loaded, X_test_model0)\n",
    "    shap_values_np=shap_values.to_numpy()\n",
    "    \n",
    "    shap_importance = np.abs(shap_values_np).mean(axis=0)\n",
    "\n",
    "    top_10_feature_indices = np.argsort(shap_importance)[-15:][::-1]\n",
    "\n",
    "    top_10_feature_names = X_test_model0.columns[top_10_feature_indices]\n",
    "\n",
    "    for feature in top_10_feature_names:\n",
    "        shap.dependence_plot(feature, shap_values_np, X_test_model0, interaction_index=None, show=False)\n",
    "        plt.axhline(y=0, color='red', linestyle='--', linewidth=1.5)\n",
    "        savename='figures/20241010_SHAP_dependence_'\n",
    "        savename+=(feature+ '.png')\n",
    "        savename=savename.replace('*','')\n",
    "        savename=savename.replace('<','')\n",
    "        savename=savename.replace('~','')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(savename,transparent=True)\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8a1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAP_dependence_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5495fe4b-edf2-4a26-9b38-ea968e56e5d5",
   "metadata": {},
   "source": [
    "# Partial dependence plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddb987f-2751-4a0f-8ae9-f7916a8fd211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import partial_dependence, PartialDependenceDisplay\n",
    "\n",
    "def PDP_plot():\n",
    "    \n",
    "    clf_loaded = joblib.load('20240820_models/ENS_classifier.pkl')\n",
    "    set_seeds(0)\n",
    "    \n",
    "    shap_values, shap_expected_value, global_shap_df = generate_shap_values(clf_loaded, X_test_model0)\n",
    "    shap_values_np = shap_values.to_numpy()\n",
    "    \n",
    "    shap_importance = np.abs(shap_values_np).mean(axis=0)\n",
    "    top_10_feature_indices = np.argsort(shap_importance)[-15:][::-1]\n",
    "    top_10_feature_names = X_test_model0.columns[top_10_feature_indices]\n",
    "    \n",
    "    for feature in top_10_feature_names:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        PartialDependenceDisplay.from_estimator(\n",
    "            clf_loaded, \n",
    "            X_test_model0, \n",
    "            [feature],\n",
    "            ax=ax\n",
    "        )\n",
    "        \n",
    "        savename = 'figures/PDP_'\n",
    "        savename += (feature + '.png')\n",
    "        savename = savename.replace('*', '')\n",
    "        savename = savename.replace('<', '')\n",
    "        savename = savename.replace('~', '')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(savename, transparent=True)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde9451f-2ad1-4203-aadc-e6ac62270931",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDP_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c0a4b2-8905-4aac-b1ba-d972a1bc643d",
   "metadata": {},
   "source": [
    "# Decision curve analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d745736-d36e-4cf6-aaeb-101244d96894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_net_benefit(y_true, y_pred_proba, threshold):\n",
    "    n = len(y_true)\n",
    "    tp = np.sum((y_pred_proba >= threshold) & (y_true == 1))\n",
    "    fp = np.sum((y_pred_proba >= threshold) & (y_true == 0))\n",
    "    net_benefit = (tp / n) - (fp / n) * (threshold / (1 - threshold))\n",
    "    return net_benefit\n",
    "\n",
    "def DCA_plot():\n",
    "    \n",
    "    clf_loaded = joblib.load('20240820_models/ENS_classifier.pkl')\n",
    "    set_seeds(0)\n",
    "    probas_ = clf_loaded.predict_proba(X_test_model0)\n",
    "    \n",
    "    thresholds = np.arange(0.01, 1.0, 0.01)\n",
    "    net_benefits = []\n",
    "    net_benefits_all = []\n",
    "    net_benefits_none = []\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        net_benefit = calculate_net_benefit(y_test, probas_[:, 1], threshold)\n",
    "        net_benefits.append(net_benefit)\n",
    "        \n",
    "        net_benefit_all = (np.sum(y_test) / len(y_test)) - (1 - np.sum(y_test) / len(y_test)) * (threshold / (1 - threshold))\n",
    "        net_benefits_all.append(net_benefit_all)\n",
    "        \n",
    "        net_benefits_none.append(0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('black')\n",
    "        spine.set_linewidth(2)\n",
    "    \n",
    "    plt.plot(thresholds, net_benefits, color='blue', label='ENS model', lw=3, alpha=1)\n",
    "    plt.plot(thresholds, net_benefits_all, color='gray', linestyle='--', label='Treat all', lw=2, alpha=0.7)\n",
    "    plt.plot(thresholds, net_benefits_none, color='black', linestyle='--', label='Treat none', lw=2, alpha=0.7)\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([min(net_benefits + net_benefits_all) - 0.05, max(net_benefits) + 0.05])\n",
    "    plt.xlabel('Threshold Probability', fontsize=16)\n",
    "    plt.ylabel('Net Benefit', fontsize=16)\n",
    "    plt.title('Decision Curve Analysis', fontsize=18)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    \n",
    "    legend = plt.legend(loc=\"upper right\", fontsize=14)\n",
    "    legend.get_frame().set_linewidth(2)\n",
    "    \n",
    "    for line in legend.get_lines():\n",
    "        line.set_linewidth(4)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/DCA.png', transparent=True)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844af67-d88d-41a0-82b0-35a30f2d8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "DCA_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc9ad5-ebd2-48b8-880c-3212c923c320",
   "metadata": {},
   "source": [
    "# Calibration curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6484382f-0b56-415e-af77-0ffac2e08a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "def calibration_plot():\n",
    "    \n",
    "    clf_loaded = joblib.load('20240820_models/ENS_classifier.pkl')\n",
    "    set_seeds(0)\n",
    "    probas_ = clf_loaded.predict_proba(X_test_model0)\n",
    "    \n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(y_test, probas_[:, 1], n_bins=10)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('black')\n",
    "        spine.set_linewidth(2)\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='gray', label='Perfect calibration', alpha=0.7)\n",
    "    plt.plot(mean_predicted_value, fraction_of_positives, marker='o', lw=3, color='blue', label='ENS model', alpha=1)\n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('Mean Predicted Probability', fontsize=16)\n",
    "    plt.ylabel('Fraction of Positives', fontsize=16)\n",
    "    plt.title('Calibration Curve', fontsize=18)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    \n",
    "    legend = plt.legend(loc=\"upper left\", fontsize=14)\n",
    "    legend.get_frame().set_linewidth(2)\n",
    "    \n",
    "    for line in legend.get_lines():\n",
    "        line.set_linewidth(4)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/calibration.png', transparent=True)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b9eddb-72ef-4e7a-b21b-45517e569a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtx4090",
   "language": "python",
   "name": "rtx4090"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
