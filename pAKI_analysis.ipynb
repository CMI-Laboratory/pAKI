{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from functools import partial\n",
    "from itertools import cycle, islice\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import warnings\n",
    "from sklearn import datasets, metrics, linear_model, svm\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.datasets import (make_moons, make_circles, make_classification, \n",
    "                             make_blobs, make_checkerboard)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              ExtraTreesClassifier, GradientBoostingClassifier, \n",
    "                              BaggingClassifier, VotingClassifier)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from scipy import interp\n",
    "from tableone import TableOne\n",
    "import shap\n",
    "from auto_shap.auto_shap import generate_shap_values\n",
    "\n",
    "def set_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207e04f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final=pd.read_csv('20240727_AKI_data.csv',encoding='cp949')\n",
    "print('total n')\n",
    "print(len(df_final))\n",
    "\n",
    "df_final_columns=list(df_final.columns)\n",
    "df_final_columns2=[x for x in df_final_columns if '_avail' not in x]\n",
    "df_final2=df_final[df_final_columns2]\n",
    "y=list(df_final2['AKI_postop_7D'])\n",
    "y2=list(df_final2['AKI_nonrecov_7D'])\n",
    "y3=list(df_final2['AKI_sustained_48'])\n",
    "y4=list(df_final2['AKI_sustained_72'])\n",
    "ThakarScore=list(df_final2['ThakarScore'])\n",
    "CKD_eGFR_stage=list(df_final2['CKD_eGFR_stage'])\n",
    "\n",
    "print('AKI incidence')\n",
    "print(np.sum(y))\n",
    "print(np.sum(y)/len(df_final2))\n",
    "print('')\n",
    "\n",
    "print('AKI nonrecovery incidence')\n",
    "print(np.sum(y2))\n",
    "print(np.sum(y2)/len(df_final2))\n",
    "print('')\n",
    "\n",
    "print('AKI_sustained_48 incidence')\n",
    "print(np.sum(y3))\n",
    "print(np.sum(y3)/len(df_final2))\n",
    "print('')\n",
    "\n",
    "print('AKI_sustained_72 incidence')\n",
    "print(np.sum(y4))\n",
    "print(np.sum(y4)/len(df_final2))\n",
    "print('')\n",
    "\n",
    "\n",
    "print('AUROC, AUPRC of ThakarScore')\n",
    "fpr, tpr, thresholds = roc_curve(y, ThakarScore)\n",
    "auroc = auc(fpr, tpr)\n",
    "precision, recall, _ = precision_recall_curve(y, ThakarScore)\n",
    "auprc = auc(recall, precision)\n",
    "print(auroc,auprc)\n",
    "\n",
    "print('AUROC, AUPRC of CKD_eGFR_stage')\n",
    "fpr, tpr, thresholds = roc_curve(y, CKD_eGFR_stage)\n",
    "auroc = auc(fpr, tpr)\n",
    "precision, recall, _ = precision_recall_curve(y, CKD_eGFR_stage)\n",
    "auprc = auc(recall, precision)\n",
    "print(auroc,auprc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d273d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 1 year\n",
    "X_trainval=df_final2.iloc[:1693]\n",
    "X_test=df_final2.iloc[1693:]\n",
    "X_trainval.reset_index(inplace=True,drop=True)\n",
    "X_test.reset_index(inplace=True,drop=True)\n",
    "\n",
    "X_trainval=X_trainval[list(X_trainval.columns)[:-5]]\n",
    "X_test=X_test[list(X_test.columns)[:-5]]\n",
    "\n",
    "X_trainval = X_trainval.drop(columns=list(X_trainval.columns)[-11:-8])\n",
    "X_test = X_test.drop(columns=list(X_test.columns)[-11:-8])\n",
    "\n",
    "yy_trainval=y[:1693]\n",
    "yy_test=y[1693:]\n",
    "\n",
    "yy2_trainval=y2[:1693]\n",
    "yy2_test=y2[1693:]\n",
    "\n",
    "yy3_trainval=y3[:1693]\n",
    "yy3_test=y3[1693:]\n",
    "\n",
    "yy4_trainval=y4[:1693]\n",
    "yy4_test=y4[1693:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5727c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainvaltest=pd.concat([X_trainval,X_test])\n",
    "y_trainvaltest=yy4_trainval+yy4_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7872dee6",
   "metadata": {},
   "source": [
    "# scenario columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8cc2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=list(X_trainval.columns)\n",
    "\n",
    "input_model0_1=columns[:34]\n",
    "input_model1_1=columns[34:40]\n",
    "input_model0_2=columns[40:62]\n",
    "input_model1_2=columns[62:87]\n",
    "etccols=columns[87:]\n",
    "input_model2_1=columns[155:-2]\n",
    "\n",
    "scenario1=[]\n",
    "scenario1.append('baseline_rSO2')\n",
    "scenario1.append('MAP_mean_list')\n",
    "scenario1.append('MAP_CV_list')\n",
    "scenario1.append('MAP_ARV_list')\n",
    "scenario1.append('MAP_duration_65_list')\n",
    "scenario1.append('MAP_duration_100_list')\n",
    "scenario1.append('MAP_auc_65_list')\n",
    "scenario1.append('MAP_auc_100_list')\n",
    "scenario1.append('PP_mean_list')\n",
    "scenario1.append('PP_duration_60_list')\n",
    "scenario1.append('PP_auc_60_list')\n",
    "scenario1.append('CVP_mean_list')\n",
    "scenario1.append('CVP_duration_12_list')\n",
    "scenario1.append('CVP_auc_12_list')\n",
    "scenario1.append('CI_mean_list')\n",
    "scenario1.append('CI_duration_2_list')\n",
    "scenario1.append('CI_auc_2_list')\n",
    "\n",
    "scenario2=[]\n",
    "scenario2.append('baseline_rSO2')\n",
    "scenario2.append('NEW_MAP_preCPB_CV_list')\n",
    "scenario2.append('NEW_MAP_preCPB_ARV_list')\n",
    "scenario2.append('NEW_PP_preCPB_mean_list')\n",
    "scenario2.append('NEW_PP_preCPB_auc_60_list')\n",
    "scenario2.append('NEW_CI_preCPB_mean_list')\n",
    "scenario2.append('NEW_CI_preCPB_auc_2_list')\n",
    "scenario2.append('NEW_MAP_intraCPB_CV_list')\n",
    "scenario2.append('NEW_MAP_intraCPB_ARV_list')\n",
    "scenario2.append('NEW_MAP_postCPB_CV_list')\n",
    "scenario2.append('NEW_MAP_postCPB_ARV_list')\n",
    "scenario2.append('NEW_PP_postCPB_mean_list')\n",
    "scenario2.append('NEW_PP_postCPB_auc_60_list')\n",
    "scenario2.append('NEW_CI_postCPB_mean_list')\n",
    "scenario2.append('NEW_CI_postCPB_auc_2_list')\n",
    "\n",
    "scenario3=[]\n",
    "scenario3.append('baseline_rSO2')\n",
    "scenario3.append('MAP_CV_list')\n",
    "scenario3.append('MAP_ARV_list')\n",
    "scenario3.append('NEW_PP_CPBMAPincluded_mean_list')\n",
    "scenario3.append('NEW_PP_CPBMAPincluded_auc_60_list')\n",
    "scenario3.append('CI_mean_list')\n",
    "scenario3.append('CI_auc_2_list')\n",
    "\n",
    "\n",
    "scenario4=[]\n",
    "scenario4.append('baseline_rSO2')\n",
    "scenario4.append('MAP_mean_list')\n",
    "scenario4.append('MAP_CV_list')\n",
    "scenario4.append('MAP_ARV_list')\n",
    "scenario4.append('MAP_duration_65_list')\n",
    "scenario4.append('MAP_duration_100_list')\n",
    "scenario4.append('MAP_auc_65_list')\n",
    "scenario4.append('MAP_auc_100_list')\n",
    "scenario4.append('PP_mean_list')\n",
    "scenario4.append('PP_duration_60_list')\n",
    "scenario4.append('PP_auc_60_list')\n",
    "scenario4.append('CVP_mean_list')\n",
    "scenario4.append('CVP_duration_12_list')\n",
    "scenario4.append('CVP_auc_12_list')\n",
    "scenario4.append('CI_mean_list')\n",
    "scenario4.append('CI_duration_2_list')\n",
    "scenario4.append('CI_auc_2_list')\n",
    "scenario4.append('NEW_MAP_intraCPB_mean_list')\n",
    "scenario4.append('NEW_MAP_intraCPB_duration_65_list')\n",
    "scenario4.append('NEW_MAP_intraCPB_duration_100_list')\n",
    "scenario4.append('NEW_MAP_intraCPB_auc_65_list')\n",
    "scenario4.append('NEW_MAP_intraCPB_auc_100_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e11247",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_model0=input_model0_1+input_model0_2\n",
    "\n",
    "input_model1=input_model0+input_model1_1+input_model1_2+scenario2\n",
    "\n",
    "input_model2=input_model1+input_model2_1\n",
    "\n",
    "X_trainval_model0=X_trainval[input_model0]\n",
    "X_trainval_model1=X_trainval[input_model1]\n",
    "X_trainval_model2=X_trainval[input_model2]\n",
    "\n",
    "X_test_model0=X_test[input_model0]\n",
    "X_test_model1=X_test[input_model1]\n",
    "X_test_model2=X_test[input_model2]\n",
    "\n",
    "\n",
    "y_trainval=np.array(yy4_trainval)\n",
    "y_test=np.array(yy4_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0dc631",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a372c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seeds(0)\n",
    "model = xgb.XGBClassifier()\n",
    "parameter_space = {\n",
    "    'n_estimators': [100, 200, 300, 400],            # Number of boosted trees to fit\n",
    "    'max_depth': [2,3, 4, 5, 6, 7, 8, 9],                      # Maximum tree depth for base learners\n",
    "    'learning_rate': [0.0001,0.001, 0.01, 0.1],        # Step size shrinkage used to prevent overfitting\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],                   # Subsample ratio of the training instance\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],            # Subsample ratio of columns when constructing each tree\n",
    "    'gamma': [0,  0.5, 1, 2, 4, 8],                    # Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    'reg_alpha': [0, 0.5, 1, 2, 4, 8],                  # L1 regularization term on weights\n",
    "    'reg_lambda': [0, 0.5, 1, 2, 4, 8],                      # L2 regularization term on weights\n",
    "    'min_child_weight': [1, 2, 3, 4]                   # Minimum sum of instance weight (hessian) needed in a child\n",
    "}\n",
    "\n",
    "folds = 4\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "              \n",
    "grid_search = GridSearchCV(model, parameter_space, scoring=['roc_auc', 'average_precision'], verbose=2, return_train_score=True, cv=skf, refit='roc_auc')\n",
    "\n",
    "grid_search.fit(X_trainval_model0, y_trainval)\n",
    "best_param = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d0adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_XGB=xgb.XGBClassifier(**best_param)\n",
    "set_seeds(0)\n",
    "classifier_XGB.fit(X_trainval_model0, y_trainval)\n",
    "probas_ = classifier_XGB.predict_proba(X_test_model0)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "print(auc(fpr, tpr))\n",
    "precision, recall, _ = precision_recall_curve(y_test, probas_[:, 1])\n",
    "print(auc(recall, precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fb72a1",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19f21a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seeds(0)\n",
    "model = RandomForestClassifier()\n",
    "parameter_space = {\n",
    "    'criterion':['log_loss','gini','entropy'],\n",
    "    'n_estimators': [25,50, 100, 150, 200,250,300],  # Number of trees\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10,12],  # Maximum tree depth\n",
    "    'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10],  # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 3, 4],  # Minimum samples required to be at a leaf node\n",
    "    'max_features': ['sqrt', 'log2', None]  # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "folds = 4\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "              \n",
    "grid_search = GridSearchCV(model, parameter_space, scoring=['roc_auc', 'average_precision'], verbose=2, return_train_score=True, cv=skf, refit='roc_auc')\n",
    "\n",
    "grid_search.fit(X_trainval_model0, y_trainval)\n",
    "best_param = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6816a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_RF=RandomForestClassifier(**best_param)\n",
    "set_seeds(0)\n",
    "classifier_RF.fit(X_trainval_model0, y_trainval)\n",
    "probas_ = classifier_RF.predict_proba(X_test_model0)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "print(auc(fpr, tpr))\n",
    "precision, recall, _ = precision_recall_curve(y_test, probas_[:, 1])\n",
    "print(auc(recall, precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b011071",
   "metadata": {},
   "source": [
    "# ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ed25b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seeds(42)\n",
    "model = et()\n",
    "parameter_space = {\n",
    "    'n_estimators': [50, 100, 150, 200,250,300],  # Number of trees\n",
    "    'criterion': ['gini', 'entropy'],  # Splitting criterion\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],  # Maximum tree depth\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum samples required to be at a leaf node\n",
    "    'max_features': ['sqrt', 'log2', None],  # Number of features to consider when looking for the best split\n",
    "    'bootstrap': [False, True],  # Whether bootstrap samples are used when building trees\n",
    "    'class_weight': [None, 'balanced']  # Weights associated with classes\n",
    "}\n",
    "\n",
    "parameter_space = {\n",
    "    'n_estimators': [50, 100, 150],  # Number of trees\n",
    "}\n",
    "\n",
    "folds = 4\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True)\n",
    "\n",
    "              \n",
    "grid_search = GridSearchCV(model, parameter_space, scoring=['roc_auc', 'average_precision'], verbose=2, return_train_score=True, cv=skf, refit='roc_auc')\n",
    "\n",
    "grid_search.fit(X_trainval_model0, y_trainval)\n",
    "best_param = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8809128",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_ET=et(**best_param)\n",
    "set_seeds(0)\n",
    "classifier_ET.fit(X_trainval_model0, y_trainval)\n",
    "probas_ = classifier_ET.predict_proba(X_test_model0)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "print(auc(fpr, tpr))\n",
    "precision, recall, _ = precision_recall_curve(y_test, probas_[:, 1])\n",
    "print(auc(recall, precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a400d9b",
   "metadata": {},
   "source": [
    "# ENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = VotingClassifier(estimators=[('XGB', classifier_XGB),('RF', classifier_RF),('ET', classifier_ET)], voting='soft')\n",
    "set_seeds(0)\n",
    "clf.fit(X_trainval_model0, y_trainval)\n",
    "probas_ = clf.predict_proba(X_test_model0)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas_[:,1])\n",
    "auroc = auc(fpr, tpr)\n",
    "precision, recall, _ = precision_recall_curve(y_test, probas_[:, 1])\n",
    "auprc = auc(recall, precision)\n",
    "print(auroc,auprc)\n",
    "joblib.dump(clf, \"20240820_models/ENS_classifier.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6692a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values, shap_expected_value, global_shap_df = generate_shap_values(clf, X_test_model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b71807",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_np=shap_values.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4549fb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_np,X_test_model0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5815acb8",
   "metadata": {},
   "source": [
    "# tableOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7631683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table1(catcolumn,catcolumns,dfdfdf2,savename):\n",
    "    nonnormallist=[]\n",
    "    def _normality(self, x):\n",
    "        #print(x.name)\n",
    "\n",
    "        if len(x.values[~np.isnan(x.values)]) >= 20:\n",
    "            p = stats.shapiro(x.values).pvalue\n",
    "        else:\n",
    "            p = None\n",
    "        # dropna=False argument in pivot_table does not function as expected\n",
    "        # return -1 instead of None\n",
    "        if pd.isnull(p):\n",
    "            return -1\n",
    "        if p<=0.05:\n",
    "            nonnormallist.append(x.name)\n",
    "        return p\n",
    "\n",
    "    TableOne._normality=_normality\n",
    "\n",
    "    def my_custom_test(group1, group2):\n",
    "        \"\"\"\n",
    "        Hypothesis test for test_self_defined_statistical_tests\n",
    "        \"\"\"\n",
    "        my_custom_test.__name__ = \"mannwhitneyu\"\n",
    "        _, pval= scipy.stats.mannwhitneyu(group1, group2)\n",
    "        return pval\n",
    "\n",
    "    nonnormallist=[]\n",
    "    def _normality(self, x):\n",
    "        #print(x.name)\n",
    "\n",
    "        if len(x.values[~np.isnan(x.values)]) >= 20:\n",
    "            p = stats.shapiro(x.values).pvalue\n",
    "        else:\n",
    "            p = None\n",
    "        # dropna=False argument in pivot_table does not function as expected\n",
    "        # return -1 instead of None\n",
    "        if pd.isnull(p):\n",
    "            return -1\n",
    "        if p<=0.05:\n",
    "            nonnormallist.append(x.name)\n",
    "        return p\n",
    "\n",
    "    TableOne._normality=_normality\n",
    "\n",
    "    table1=TableOne(dfdfdf2,categorical=catcolumns,groupby=[catcolumn],normal_test=True,pval=True,htest_name=True,decimals=3)\n",
    "    nonnormallist=list(set(nonnormallist))\n",
    "    nonnormallist\n",
    "\n",
    "    table1=TableOne(dfdfdf2,categorical=catcolumns,groupby=[catcolumn],normal_test=True,pval=True,htest_name=True,nonnormal=nonnormallist,decimals=3)\n",
    "    try:\n",
    "        os.mkdir(newtablename)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.mkdir(newtablename+'/table1')\n",
    "    except:\n",
    "        pass\n",
    "    catcolumn=catcolumn.replace(' ','_')\n",
    "    catcolumn=catcolumn.replace('/','_')\n",
    "    table1.to_html('figures/table1_'+savename+'.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical=[]\n",
    "categorical.append('op_type')\n",
    "categorical.append('re-do')\n",
    "categorical.append('sex')\n",
    "categorical.append('emergency')\n",
    "categorical.append('VAD_use')\n",
    "categorical.append('HTN')\n",
    "categorical.append('CKD')\n",
    "categorical.append('old CVA')\n",
    "categorical.append('DM')\n",
    "categorical.append('A.fib')\n",
    "categorical.append('liver cirrhosis')\n",
    "categorical.append('CHF')\n",
    "categorical.append('old MI')\n",
    "categorical.append('COPD')\n",
    "categorical.append('Functional class')\n",
    "categorical.append('acuteMI (1WK)')\n",
    "categorical.append('NYHA')\n",
    "categorical.append('BB')\n",
    "categorical.append('CCB')\n",
    "categorical.append('ACEi')\n",
    "categorical.append('ARB')\n",
    "categorical.append('Statin')\n",
    "categorical.append('diuretics')\n",
    "categorical.append('Warfarin')\n",
    "categorical.append('heparinization')\n",
    "categorical.append('NOAC')\n",
    "categorical.append('vaso_T')\n",
    "categorical.append('prima_T_bi')\n",
    "categorical.append('dobu_T_bi')\n",
    "categorical.append('Katz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c0d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainvaltest2=X_trainvaltest.copy()\n",
    "X_trainvaltest2['y']=y_trainvaltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90890c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table1('y',categorical,X_trainvaltest2, 'y4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a77198",
   "metadata": {},
   "source": [
    "# ROC PR curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6299bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_PR_curves(roc_pr):\n",
    "    fig, ax =plt.subplots(figsize=(25,25))\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('black')\n",
    "        spine.set_linewidth(2)  # Adjust the line width as needed\n",
    "\n",
    "    if roc_pr=='ROC':\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',alpha=1)\n",
    "    plt.xticks(fontsize=28)\n",
    "    plt.yticks(fontsize=28)\n",
    "    \n",
    "\n",
    "    clf_loaded = joblib.load('20240820_models/ENS_classifier.pkl')\n",
    "    set_seeds(0)\n",
    "    probas_ = clf_loaded.predict_proba(X_test_model0)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
    "    auroc = round(auc(fpr, tpr),3)\n",
    "    precision, recall, _ = precision_recall_curve(y_test, probas_[:, 1])\n",
    "    auprc = round(auc(recall, precision),3)\n",
    "            \n",
    "    linewidth=3\n",
    "    \n",
    "    if roc_pr=='ROC':\n",
    "        plt.plot(fpr, tpr, color='blue',label=f'ENS model AUROC = {auroc}' ,lw=linewidth, alpha=1)\n",
    "    if roc_pr=='PR':\n",
    "        plt.plot(recall, precision, color='blue',label=f'ENS model AUPRC = {auprc}' ,lw=linewidth, alpha=1)\n",
    "    \n",
    "    plt.xlim([-0.00, 1.00])\n",
    "    plt.ylim([-0.00, 1.00])\n",
    "    plt.yticks(np.arange(0.2, 1.2, step=0.2))\n",
    "    plt.xticks(fontsize =37)\n",
    "    plt.yticks(fontsize =37)\n",
    "    \n",
    "    if roc_pr == 'ROC':\n",
    "        plt.xlabel('1-Specificity', fontsize=50)\n",
    "        plt.ylabel('Sensitivity', fontsize=50)\n",
    "        plt.title('ROC curves', fontsize=55)\n",
    "        legend = plt.legend(loc=\"lower right\", fontsize=45)\n",
    "    if roc_pr == 'PR':\n",
    "        plt.xlabel('Recall', fontsize=50)\n",
    "        plt.ylabel('Precision', fontsize=50)\n",
    "        plt.title('PR curves', fontsize=55)\n",
    "        legend = plt.legend(loc=\"upper right\", fontsize=45)\n",
    "    \n",
    "    # Set line width of legend box\n",
    "    legend.get_frame().set_linewidth(4)\n",
    "    \n",
    "    # Set line width of legend lines\n",
    "    for line in legend.get_lines():\n",
    "        line.set_linewidth(8)  # Adjust the line width as needed\n",
    "    \n",
    "    if roc_pr == 'ROC':\n",
    "        plt.savefig('figures/20230821_ROC.png', transparent=True)\n",
    "        plt.show()\n",
    "    if roc_pr == 'PR':\n",
    "        plt.savefig('figures/20230821_PR.png', transparent=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bad2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rocprtemp in ['ROC','PR']:\n",
    "    ROC_PR_curves(roc_pr=rocprtemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904459b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "739d7c40",
   "metadata": {},
   "source": [
    "# SHAP summary plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SHAP_summary_plot():\n",
    "    \n",
    "    clf_loaded = joblib.load('20240820_models/ENS_classifier.pkl')\n",
    "    set_seeds(0)\n",
    "\n",
    "    shap_values, shap_expected_value, global_shap_df = generate_shap_values(clf_loaded, X_test_model0)\n",
    "    shap_values_np=shap_values.to_numpy()\n",
    "\n",
    "    shap.summary_plot(shap_values_np,X_test_model0,max_display=10,show=False)\n",
    "    savename='figures/20241010_SHAP_summary.png'\n",
    "    plt.savefig(savename,transparent=True)\n",
    "\n",
    "    plt.close()\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69489fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAP_summary_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477ac8d1",
   "metadata": {},
   "source": [
    "# SHAP dependence plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SHAP_dependence_plot(X_test,model_type,scenario_num, y_trainval, y_test,excludelistnum,ytype,seednum):\n",
    "\n",
    "    clf_loaded = joblib.load('20240820_models/ENS_classifier.pkl')\n",
    "    set_seeds(0)\n",
    "   \n",
    "    shap_values, shap_expected_value, global_shap_df = generate_shap_values(clf_loaded, X_test_model0)\n",
    "    shap_values_np=shap_values.to_numpy()\n",
    "    \n",
    "    shap_importance = np.abs(shap_values_np).mean(axis=0)\n",
    "\n",
    "    top_10_feature_indices = np.argsort(shap_importance)[-15:][::-1]\n",
    "\n",
    "    top_10_feature_names = X_test_model0.columns[top_10_feature_indices]\n",
    "\n",
    "    for feature in top_10_feature_names:\n",
    "        shap.dependence_plot(feature, shap_values_np, X_test_model0, interaction_index=None, show=False)\n",
    "        plt.axhline(y=0, color='red', linestyle='--', linewidth=1.5)\n",
    "        savename='figures/20241010_SHAP_dependence_'\n",
    "        savename+=(feature+ '.png')\n",
    "        savename=savename.replace('*','')\n",
    "        savename=savename.replace('<','')\n",
    "        savename=savename.replace('~','')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(savename,transparent=True)\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8a1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAP_dependence_plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtx4090",
   "language": "python",
   "name": "rtx4090"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
